\begin{center}
  \Large{\textbf{ABSTRACT}}\\
\end{center}
\vspace{1cm}
Automated stock trading faces significant challenges due to market complexity, volatility, and the difficulty of incorporating qualitative information like market sentiment into quantitative models. Traditional trading strategies, such as technical and fundamental analysis, often struggle with sudden market shifts driven by news or sentiment, while pure quantitative models may overlook valuable textual information. Reinforcement Learning has emerged as a promising approach for optimizing trading decisions, yet it typically relies on numerical data and may require large amounts of data. Conversely, Large Language Models excel at understanding textual nuances and extracting sentiment from financial news, but they do not inherently make trading decisions, and their integration into robust trading frameworks is an active research area. Existing solutions often treat these components in isolation, limiting their collective potential. This thesis addresses these limitations by proposing an LLM-Augmented Reinforcement Learning framework for automatic stock trading. This approach was chosen to effectively combine the sequential reasoning strengths of Reinforcement Learning with the deep contextual understanding and sentiment extraction capabilities of Large Language Models. The proposed methods outperform both vanilla Reinforcement Learning agents and traditional trading methods.
\begin{flushright}
  \begin{tabular}{@{}c@{}}
    Student\\
    \textit{(Signature and full name)}
  \end{tabular}
\end{flushright}
