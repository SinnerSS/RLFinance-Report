\section{Summary}
This thesis successfully demonstrated the potential of LLM-augmented reinforcement learning for automatic stock trading, addressing the challenge of creating an autonomous agent capable of navigating the complex and uncertain dynamics of modern equity markets. The core problem tackled was the integration of quantitative market data with qualitative sentiment signals derived from financial news, aiming to enhance the decision-making capabilities of a trading agent. The research detailed the development of a comprehensive pipeline, starting from the acquisition of historical price data and financial news, through the extraction of sentiment scores using a large language model (DeepSeek-V3) with carefully engineered prompts, to the construction of a feature set combining technical indicators and these novel sentiment metrics. This integrated information was then used to train a \gls{SAC} agent within a \gls{POMDP} framework, where a sentiment-shaped reward function guided the agent's learning process. The experimental results presented in Chapter \ref{chap:result} compellingly showed that the proposed \gls{LLM}-\gls{SAC} agent significantly outperformed a range of baseline strategies, including traditional portfolio allocation methods like \gls{BaH}, \gls{UP}, \gls{CORN}, and \gls{ANTICOR}, as well as standard \gls{RL} agents (PPO and vanilla SAC) that lacked access to \gls{LLM}-derived sentiment. The \gls{LLM}-\gls{SAC} agent achieved superior cumulative returns, annualized returns, and risk-adjusted returns as measured by the Sharpe Ratio, validating the hypothesis that incorporating sentiment signals can lead to more profitable trading strategies.

Despite these promising results, the study acknowledges certain limitations inherent in its scope and methodology. The evaluation was conducted entirely through historical backtesting, which, while extensive, does not fully replicate the complexities of live trading, such as order execution delays, slippage, and real-time market impact. The research was also confined to a specific asset universe, the Nasdaq-100, and operated from a single-agent perspective, without modeling the strategic interactions of other market participants. Furthermore, while the \gls{LLM}-\gls{SAC} agent demonstrated improved \gls{MDD} compared to its \gls{RL} counterparts, the underwater plot indicated periods of significant drawdown, particularly during adverse market conditions, suggesting ongoing challenges in robust risk management across all market regimes. The computational demands of large language models and the continuous need to ensure their accurate interpretation of financial texts, avoiding potential biases or hallucinations, also remain pertinent considerations for practical deployment.

\section{Suggestion for Future Works}
Building upon the foundations laid by this research, several avenues for future work could further enhance the capabilities and robustness of \gls{LLM}-augmented \gls{RL} trading systems. One immediate and crucial direction involves transitioning the developed agent from a backtesting environment to live or paper trading scenarios. This step would provide invaluable insights into real-world performance and highlight practical challenges related to data ingestion, execution latency, and transaction costs not fully captured in simulations. Expanding the asset universe beyond the Nasdaq-100 to include other domestic or international equities, different asset classes like commodities or forex, or even cryptocurrencies could test the generalizability of the approach and potentially unlock new diversification benefits.

Further refinement of the \gls{LLM} integration itself presents numerous opportunities. Future research could explore more sophisticated applications of \gls{LLM}s, such as their use in generating textual explanations for trading decisions, thereby improving transparency, or in summarizing complex financial reports and macroeconomic news to create richer state representations for the \gls{RL} agent. Fine-tuning \gls{LLM}s on larger, specialized financial corpora or on dialogues specifically related to trading strategies might enhance their contextual understanding and the quality of extracted sentiment or other relevant signals. Experimentation with dynamically adaptive prompting techniques, where the nature of information requested from the \gls{LLM} changes based on market volatility or agent performance, could also prove beneficial.

From the \gls{RL} perspective, future research could focus on incorporating more advanced risk management protocols directly into the agent's learning objective or action space, potentially moving beyond traditional drawdown metrics to optimize for risk measures like Conditional Value at Risk (CVaR). Investigating hierarchical \gls{RL} structures, where a higher-level agent might determine strategic asset allocations or risk budgets based on \gls{LLM}-derived macro insights, while lower-level agents handle tactical execution, could lead to more scalable and sophisticated systems. Moreover, exploring transfer learning or meta-learning techniques could enable agents to adapt more quickly to new assets or evolving market dynamics. The integration of a wider array of alternative data sources, such as social media sentiment, geopolitical risk indices, or even satellite imagery data, processed and interpreted by \gls{LLM}s, could provide additional predictive power. Finally, continued efforts to improve the explainability of both the \gls{LLM}'s textual analysis and the \gls{RL} agent's decision-making process will be vital for building trust and facilitating the adoption of such advanced AI-driven trading systems.
